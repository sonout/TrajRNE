{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from shapely.geometry import LineString\n",
    "from shapely import wkt\n",
    "import numpy as np\n",
    "import swifter\n",
    "from preprocess import *\n",
    "from preprocess import remove_outlier_trajectories\n",
    "from road_network import RoadNetwork\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network\n",
    "network = RoadNetwork(\"Porto, Portugal\", network_type=\"drive\", retain_all=True, truncate_by_edge=True)\n",
    "network.save(path=\"../osm_data/sf\")\n",
    "\n",
    "# After saving can be loaded like this:\n",
    "#network = RoadNetwork()\n",
    "#network.load(\"../osm_data/sf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data \n",
    "\n",
    "all_files = glob.glob(os.path.join(\"../datasets/trajectories/sf/cabdata\" , \"*.txt\"))\n",
    "\n",
    "data = []\n",
    "\n",
    "for filename in all_files:\n",
    "    tdf = pd.read_csv(filename, index_col=None, header=None, delimiter=\" \")\n",
    "    tdf[\"tax_id\"] = filename.split(\"/\")[-1].split(\".\")[0].split(\"_\")[1]\n",
    "    data.append(tdf)\n",
    "\n",
    "df = pd.concat(data, axis=0, ignore_index=True)\n",
    "df = df.rename(columns={0: \"lat\", 1: \"long\", 2: \"occupied\", 3: \"timestamp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time \n",
    "# group for each taxi\n",
    "rows = []\n",
    "for _, g in tqdm(df.groupby(\"tax_id\")):\n",
    "    # group each occupied trajectory\n",
    "    trajectories_occu = g[g['occupied'] == 1].groupby((g['occupied'] != 1).cumsum())\n",
    "    # trajectories_nooccu = g[g['occupied'] == 0].groupby((g['occupied'] != 0).cumsum())\n",
    "    for _, t in trajectories_occu:\n",
    "        if t.shape[0] < 5:\n",
    "            continue\n",
    "        data = t.to_numpy()\n",
    "        data[:, 0], data[:, 1] = data[:, 1], data[:, 0].copy()\n",
    "        seq = LineString(data[::-1, :2].astype(np.float32))\n",
    "        stamps = data[::-1, 3]\n",
    "        rows.append((seq, stamps - stamps[0]))\n",
    "    \n",
    "    # for _, t in trajectories_nooccu:\n",
    "    #     if t.shape[0] < 5:\n",
    "    #         continue\n",
    "    #     data = t.to_numpy()\n",
    "    #     seq = LineString(data[::-1, :2])\n",
    "    #     rows.append((seq, data[::-1, 3]))\n",
    "\n",
    "processed_df = pd.DataFrame(rows, columns=[\"POLYLINE\", \"timestamp\"])\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../datasets/trajectories/sf/all_gps_points.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_bounds = network.bounds\n",
    "clipped = clip_trajectories(processed_df.copy(), city_bounds, polyline_convert=True)\n",
    "# df_clipped = filter_min_points(df_clipped, 5)\n",
    "clipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Correct timestamps\n",
    "\"\"\"\n",
    "\n",
    "def strictly_increasing(L):\n",
    "    return all(x+20>=y for x, y in zip(L, L[1:]))\n",
    "\n",
    "\n",
    "def correct_timestamps(traj, orig_trajs, orig_ts):\n",
    "    corrected_ts = []\n",
    "    corrected_traj = []\n",
    "    idxs = []\n",
    "    found = False\n",
    "    for i, g1 in enumerate(traj):\n",
    "        ridx = 0\n",
    "        for j, g2 in enumerate(orig_trajs[ridx:]):\n",
    "            if g1 == g2:\n",
    "                found = True\n",
    "                corrected_ts.append(orig_ts[j])\n",
    "                corrected_traj.append(g1)\n",
    "                idxs.append(j)\n",
    "                ridx = j+1\n",
    "                break\n",
    "            # if found:\n",
    "            #     break\n",
    "\n",
    "    assert len(corrected_traj) == len(corrected_ts)\n",
    "    # assert strictly_increasing(idxs), (idxs)\n",
    "    \n",
    "    return corrected_traj, (np.array(corrected_ts) - corrected_ts[0]).astype(int).tolist()\n",
    "\n",
    "\n",
    "rows = []\n",
    "i = 0\n",
    "orig_polies, orig_ts = processed_df.POLYLINE, processed_df.timestamp\n",
    "for i, r in tqdm(clipped.iterrows()):\n",
    "    op = list(orig_polies.loc[r.name].coords)\n",
    "    ot = orig_ts.loc[r.name]\n",
    "    if type(r.POLYLINE) == LineString:\n",
    "        traj = list(r.POLYLINE.coords)\n",
    "        if len(traj) < 5:\n",
    "            continue\n",
    "        ctraj, cts = correct_timestamps(traj, op, ot)\n",
    "        if len(ctraj) < 5:\n",
    "            continue\n",
    "        rows.append([LineString(ctraj), cts])\n",
    "    else:\n",
    "        for line in r.POLYLINE:\n",
    "            traj = list(line.coords)\n",
    "            if len(traj) < 5:\n",
    "                continue\n",
    "            ctraj, cts = correct_timestamps(traj, op, ot)\n",
    "            if len(ctraj) < 5:\n",
    "                continue\n",
    "            rows.append([LineString(ctraj), cts])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"POLYLINE\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"id\"] = np.arange(1, df.shape[0]+1)\n",
    "df[\"timestamp\"] = df[\"timestamp\"].astype(str)\n",
    "df[\"timestamp\"] = df[\"timestamp\"].str.replace(\"[\", \"\")\n",
    "df[\"timestamp\"] = df[\"timestamp\"].str.replace(\"]\", \"\")\n",
    "# df_clipped[\"timestamp\"] = df[\"timestamp\"].str.replace(\" \", \", \")\n",
    "df.to_csv(\"../datasets/trajectories/sf/mapped_id_poly_clipped_corrected.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/trajectories/sf/mapped_id_poly_clipped_corrected.csv\", sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.iloc[418135].POLYLINE.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"POLYLINE\"] = df[\"POLYLINE\"].swifter.apply(wkt.loads)\n",
    "gdf = gpd.GeoDataFrame(df, crs=\"epsg:4326\", geometry=\"POLYLINE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map Matching\n",
    "\n",
    "Next we need to map match the trajectories. We use FastMapMatching (https://fmm-wiki.github.io/). For faster map matching, we recommend using the command line programm instead of the python wrapper, which is used in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.fmm_trajectorie_mapping(\n",
    "    network_file=\"../osm_data/sf/edges.shp\",\n",
    "    input_file=\"../datasets/trajectories/SF/mapped_id_poly_clipped.csv\",\n",
    "    output_file=\"../datasets/trajectories/SF/road-segment-mapping.txt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the mapping especially the speed and distance values need to be verified\n",
    "df = pd.read_csv(\"../datasets/trajectories/SF/road_segment_map_final.csv\", sep=\";\")\n",
    "df_prep = remove_outlier_trajectories(df.copy(), min_edges_traversed=3)\n",
    "df_prep.to_csv(\"../datasets/trajectories/SF/road_segment_map_final.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/trajectories/SF/road_segment_map_final.csv\", sep=\";\")\n",
    "df = df[df[\"speed_mean\"] * 111000 * 3.6 < 100]\n",
    "df.to_csv(\"../datasets/trajectories/SF/road_segment_map_final.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Test of Travel Time Dataset generation\n",
    "\"\"\"\n",
    "from trajectory import Trajectory\n",
    "\n",
    "traj = Trajectory(\"../datasets/trajectories/sf/road_segment_map_final.csv\", nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"../datasets/trajectories/sf/road_segment_map_final_corrected_sf.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = traj.generate_TTE_datatset()\n",
    "dft[\"travel_time\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete corrupt trajs and save\n",
    "temp = temp[~temp[\"id\"].isin(dft[dft[\"travel_time\"] <= 10][\"id\"].values)]\n",
    "temp.to_csv(\"../datasets/trajectories/sf/road_segment_map_final.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate traj features \n",
    "\"\"\"\n",
    "features = traj.generate_speed_features(network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[features[\"avg_speed\"] < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.to_csv(\"../datasets/trajectories/sf/speed_features_unnormalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/trajectories/SF/road_segment_map_final.csv\", sep=\";\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "088070de2c6b4023b2f7ae556c412f86bcd02589c7bdb3766a0caf3cf4813fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
